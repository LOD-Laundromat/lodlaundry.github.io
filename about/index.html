
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="SPARQL endpoint of the LOD Laundromat">
    <meta name="author" content="Laurens Rietveld">
    <link rel="icon" href="/imgs/laundry.ico">
    <title>About</title>

    <!-- Bootstrap core CSS -->
    <link href="/bower_components/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="/bower_components/YASQE/dist/yasqe.min.css" rel="stylesheet">
    <link href="/bower_components/YASR/dist/yasr.min.css" rel="stylesheet">
    <link href="/style.css" rel="stylesheet">
    <link href="about.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <link rel="stylesheet" href="/bower_components/github-fork-ribbon-css/gh-fork-ribbon.ie.css">
    <![endif]-->
  </head>
  <body>
	  <div id="pageHeader" class="navbar navbar-default navbar-fixed-top bs-docs-nav">
		<div class="container">
			<div class="navbar-header">
			  <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			  </button>
			</div>
			<nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
				<ul id='topNavBar' class="nav navbar-nav">
				</ul>
			</nav>
		</div>
	</div>
    <div class="jumbotron" style="height:100%; position:relative;">
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <img
                alt="Dev Corner"
                class="mediumLogo"
                src="/imgs/laundryLine.png"
            >
          </div>
          <div class="col-md-8" style="vertical-align: middle;">
            <h1>About</h1>
            <p>
             What exactly do you publish, how do you do it, and what can I do with it?  
            </p>
          </div>
        </div>
      </div>
    </div>
  
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h2>Data</h2>
            <p>Download the cleaned datasets either via the <a href="/wardrobe">website</a>, or using your own script. To get your script to work, all you need to do is query our <a href="/sparql">SPARQL endpoint</a> to retrieve the identifier (MD5 hash) of the dataset URL, and download the file from <code>http://download.lodlaundromat.org/&lt;md5&gt;</code></p>
            <p>
            Access to the meta-data is possible via the <a href="/sparql">SPARQL endpoint</a>, or using our daily snapshots. We provide a daily snapshot of all the crawling data (including references to the cleaned files) <a href="http://download.lodlaundromat.org/dump.nt.gz">here</a>.
            </p>
            
          	<h2>Code</h2>
          	The part of the LOD Laundromat we use for crawling is called the LOD WashingMachine, and is freely available on <a href="https://github.com/LODLaundry/llWashingMachine" target="_blank">Github</a>.
          	The <a href="https://github.com/LODLaundry" target="_blank">LOD Laundromat GitHub organization</a> contains other interesting repositories as well, from example (fast) parser implementations, to examples on how you might use the LOD Laundromat for analyzing many sets of Linked Data.
          	<h2>Publications</h2>
          	
			<ul>
			<li>Beek, W. & Rietveld, L & Bazoobandi, H.R. & Wielemaker, J. & Schlobach, S.: LOD Laundromat: A Uniform Way of Publishing Other People's Dirty Data. Proceedings of the International Semantic Web Conference (2014). <a class="btn-small" href="/pdf/LOD_Laundromat_-_A_Uniform_Way_of_Publishing_Other_Peoples_Dirty_Data.pdf" target="_blank">pdf</a>
			<div class="well">
It is widely accepted that <i>proper</i> data publishing is difficult.
The majority of Linked Open Data (LOD) does not meet
even a core set of data publishing guidelines.
Moreover, datasets that are <i>clean</i> at creation,
can get <i>stains</i> over time.
As a result, the LOD cloud now contains a high level of <i>dirty</i> data
that is difficult for humans to clean and for machines to process.<br>

Existing solutions for cleaning data (standards, guidelines, tools)
are targeted towards human data creators,
who can (and do) choose not to use them.
This paper presents the LOD Laundromat, which removes stains from data
without any human intervention.
This fully automated approach is able to make very large amounts of LOD
more easily available for further processing <i>right now</i>.<br>

The LOD Laundromat is not a new dataset,
but rather a uniform point of entry to a collection of cleaned siblings
of existing datasets.
It provides researchers and application developers a wealth of data
that is guaranteed to conform to a specified set of best practices,
thereby greatly improving the chance of data actually being (re)used.

</div></li>
			</ul>
            <h2>FAQ</h2>
            <div class="faqItem">
	            <p class="question">What exactly do you publish?</p>
	            <p class="answer">We publish the crawled data as <a href="/wardrobe">gzipped N-Triples</a>, and the provenance and VoiD meta-data via our <a href="/sparql">SPARQL endpoint</a></p>
            </div>
            <div class="faqItem">
	            <p class="question">Why do you publish this?</p>
	            <p class="answer">Using and finding Linked Data takes time and effort. We are not yet at a point where all available Linked Data is clean, standard and easy to use. Many datasets contain syntax errors, duplicates, or are difficult to find.
	            We offer one single download location for Linked Data, and publish the Linked Data in a consistent simple (sorted) N-Triple format, making it easy to use and compare datasets</p>
            </div>
            <div class="faqItem">
	            <p class="question">Why Gzipped N-Triples?</p>
	            <p class="answer">Compared to hosting the whole LOD cloud via a SPARQL endpoint, hosting gzipped N-Triples is easy and doable</p>
            </div>
            <div class="faqItem">
	            <p class="question">How do I <i>use</i> these files?</p>
	            <p class="answer">Depends on what you would like to do. If you would like to use it in a triple-store, simply unzip the data. However, if you would like to analyze the triples using your own code, make sure you take advantage of the way we publish the data.

	            </p>
   	            <ol>
	            <li>The data is gzipped: you do not have to unpack everything to analyze it. Instead, you can stream it! This will save you a lot of memory usage</li>
	            <li>The data is in one single N-Triple format: using this knowledge, you can easily write your own super-fast parser, as you don't have to consider the complete scope of the N-Triple specification. 
	            And even better, <a href="https://github.com/LODLaundry/GettingStarted" target="_blank">we provide a couple of parser implementations for you!</a> (in NodeJs, Java, and Python).
	            </ol>
            </div>
  
            
          </div>
        </div>
      </div>
  
    <!--
        Bootstrap core JavaScript
        Placed at the end of the document so the pages load faster
    -->
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="/bower_components/d3/d3.min.js"></script>
    <script src="/bower_components/YASR/dist/yasr.min.js"></script>
    <script src="/bower_components/YASQE/dist/yasqe.min.js"></script>
    <script src="/main.js"></script>
  </body>
</html>

